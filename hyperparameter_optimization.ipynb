{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimization for Neural Apoptosis\n",
    "\n",
    "**Goal:** Find optimal hyperparameters for neuron-level apoptosis strategies\n",
    "\n",
    "**Strategies tested:**\n",
    "1. Standard Neuron Apoptosis (mutation-based)\n",
    "2. Functional Preservation Apoptosis (output matching)\n",
    "3. Hybrid Growth and Death (constant capacity evolution)\n",
    "\n",
    "**Status:** See `EXPERIMENT_LOG.md` for previous results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.9.0\n",
      "CUDA available: False\n",
      "MPS available: True\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to path for imports\n",
    "sys.path.insert(0, str(Path.cwd() / 'src'))\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"MPS available: {torch.backends.mps.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS (Apple Silicon GPU)\n",
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "# Device selection (prioritize MPS for M2 Max)\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "    print(\"Using MPS (Apple Silicon GPU)\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(\"Using CUDA\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Shakespeare dataset...\n",
      "Dataset size: 1,115,394 characters\n",
      "Preview: First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you\n"
     ]
    }
   ],
   "source": [
    "# Simple character-level tokenizer\n",
    "class CharTokenizer:\n",
    "    def __init__(self, text):\n",
    "        chars = sorted(list(set(text)))\n",
    "        self.vocab_size = len(chars)\n",
    "        self.stoi = {ch: i for i, ch in enumerate(chars)}\n",
    "        self.itos = {i: ch for i, ch in enumerate(chars)}\n",
    "    \n",
    "    def encode(self, text):\n",
    "        return [self.stoi[c] for c in text]\n",
    "    \n",
    "    def decode(self, tokens):\n",
    "        return ''.join([self.itos[i] for i in tokens])\n",
    "\n",
    "# Dataset\n",
    "class CharDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, text, tokenizer, seq_len=128):\n",
    "        self.data = torch.tensor(tokenizer.encode(text), dtype=torch.long)\n",
    "        self.seq_len = seq_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.seq_len\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data[idx:idx + self.seq_len]\n",
    "        y = self.data[idx + 1:idx + self.seq_len + 1]\n",
    "        return x, y\n",
    "\n",
    "# Load Shakespeare\n",
    "import urllib.request\n",
    "url = 'https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt'\n",
    "print(\"Downloading Shakespeare dataset...\")\n",
    "with urllib.request.urlopen(url) as response:\n",
    "    shakespeare_text = response.read().decode('utf-8')\n",
    "\n",
    "print(f\"Dataset size: {len(shakespeare_text):,} characters\")\n",
    "print(f\"Preview: {shakespeare_text[:200]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 65\n",
      "Dataset length: 1,115,266 sequences\n"
     ]
    }
   ],
   "source": [
    "# Create tokenizer and dataset\n",
    "tokenizer = CharTokenizer(shakespeare_text)\n",
    "shakespeare_dataset = CharDataset(shakespeare_text, tokenizer, seq_len=128)\n",
    "\n",
    "print(f\"Vocabulary size: {tokenizer.vocab_size}\")\n",
    "print(f\"Dataset length: {len(shakespeare_dataset):,} sequences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters: 1,222,977\n"
     ]
    }
   ],
   "source": [
    "# Simple Transformer\n",
    "class ApoptoticTransformer(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model=128, n_heads=4, n_layers=6, max_seq_len=128, enable_apoptosis=False):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_embedding = nn.Embedding(max_seq_len, d_model)\n",
    "        \n",
    "        self.blocks = nn.ModuleList([\n",
    "            TransformerBlock(d_model, n_heads) for _ in range(n_layers)\n",
    "        ])\n",
    "        \n",
    "        self.ln_f = nn.LayerNorm(d_model)\n",
    "        self.head = nn.Linear(d_model, vocab_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        B, T = x.shape\n",
    "        \n",
    "        tok_emb = self.embedding(x)\n",
    "        pos_emb = self.pos_embedding(torch.arange(T, device=x.device))\n",
    "        x = tok_emb + pos_emb\n",
    "        \n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        \n",
    "        x = self.ln_f(x)\n",
    "        logits = self.head(x)\n",
    "        return logits\n",
    "    \n",
    "    def get_num_params(self):\n",
    "        return sum(p.numel() for p in self.parameters())\n",
    "\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, d_model, n_heads):\n",
    "        super().__init__()\n",
    "        self.attention = nn.MultiheadAttention(d_model, n_heads, batch_first=True)\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(d_model, 4 * d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * d_model, d_model)\n",
    "        )\n",
    "        self.ln1 = nn.LayerNorm(d_model)\n",
    "        self.ln2 = nn.LayerNorm(d_model)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Attention\n",
    "        attn_out, _ = self.attention(x, x, x, need_weights=False)\n",
    "        x = x + attn_out\n",
    "        x = self.ln1(x)\n",
    "        \n",
    "        # FFN\n",
    "        ffn_out = self.ffn(x)\n",
    "        x = x + ffn_out\n",
    "        x = self.ln2(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Test model creation\n",
    "test_model = ApoptoticTransformer(\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    "    d_model=128,\n",
    "    n_heads=4,\n",
    "    n_layers=6,\n",
    "    max_seq_len=128\n",
    ").to(device)\n",
    "\n",
    "print(f\"Model parameters: {test_model.get_num_params():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Apoptosis Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Neuron-level apoptosis system loaded!\n",
      "✓ Neuron-level apoptosis system loaded!\n",
      "✓ Smooth apoptosis strategies loaded!\n",
      "\n",
      "Available strategies:\n",
      "  1. GradualFadeApoptosis - Fade neurons over 50 steps\n",
      "  2. ContinuousTurnoverApoptosis - 2% every 100 steps\n",
      "  3. DistillationApoptosis - Train new neurons first\n",
      "  4. FunctionalPreservationApoptosis - Preserve function\n",
      "\n",
      "Run compare_strategies() to test all!\n",
      "✓ Growth-only strategies loaded!\n",
      "\n",
      "Available:\n",
      "  1. GrowthOnlyManager - Add neurons, never remove\n",
      "  2. HybridGrowthAndDeath - Constant turnover (birth = death)\n",
      "✓ Genetic crossover strategy loaded!\n",
      "\n",
      "Usage:\n",
      "  # Create crossover manager\n",
      "  crossover_mgr = CrossoverApoptosis(\n",
      "      model=model,\n",
      "      target_layers=[f'blocks.{i}.ffn.0' for i in range(6)],\n",
      "      prune_rate=0.10,\n",
      "      apoptosis_interval=500,\n",
      "      crossover_mode='uniform',  # or 'fitness_weighted', 'random'\n",
      "      mutation_strength=0.1\n",
      "  )\n",
      "\n",
      "  # Use in training loop\n",
      "  crossover_mgr.step()\n",
      "\n",
      "Crossover modes:\n",
      "  - uniform: 50/50 blend of parents\n",
      "  - fitness_weighted: Higher fitness parent contributes more\n",
      "  - random: Random ratio between 30-70%\n",
      "✓ Smooth apoptosis strategies loaded!\n",
      "\n",
      "Available strategies:\n",
      "  1. GradualFadeApoptosis - Fade neurons over 50 steps\n",
      "  2. ContinuousTurnoverApoptosis - 2% every 100 steps\n",
      "  3. DistillationApoptosis - Train new neurons first\n",
      "  4. FunctionalPreservationApoptosis - Preserve function\n",
      "\n",
      "Run compare_strategies() to test all!\n",
      "✓ Growth-only strategies loaded!\n",
      "\n",
      "Available:\n",
      "  1. GrowthOnlyManager - Add neurons, never remove\n",
      "  2. HybridGrowthAndDeath - Constant turnover (birth = death)\n",
      "✓ Hyperparameter sweep system loaded!\n",
      "\n",
      "Usage:\n",
      "  # Full sweep (may take hours)\n",
      "  sweep = HyperparameterSweep(\n",
      "      model_class=ApoptoticTransformer,\n",
      "      train_dataset=shakespeare_dataset,\n",
      "      val_dataset=shakespeare_dataset,\n",
      "      device=device,\n",
      "      num_steps=2000\n",
      "  )\n",
      "  sweep.run_sweep()\n",
      "\n",
      "  # Quick sweep (10-15 configs, ~1 hour)\n",
      "  quick_sweep = QuickSweep(...same args...)\n",
      "  quick_sweep.run_sweep()\n",
      "✓ All apoptosis strategies loaded!\n"
     ]
    }
   ],
   "source": [
    "# Import from src/ package\n",
    "from neuron_apoptosis_fixed import NeuronApoptosisManager\n",
    "from smooth_apoptosis import FunctionalPreservationApoptosis\n",
    "from growth_only_strategy import HybridGrowthAndDeath\n",
    "from hyperparameter_sweep import HyperparameterSweep, QuickSweep\n",
    "\n",
    "print(\"✓ All apoptosis strategies loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Hyperparameter sweep system loaded!\n",
      "\n",
      "Usage:\n",
      "  # Full sweep (may take hours)\n",
      "  sweep = HyperparameterSweep(\n",
      "      model_class=ApoptoticTransformer,\n",
      "      train_dataset=shakespeare_dataset,\n",
      "      val_dataset=shakespeare_dataset,\n",
      "      device=device,\n",
      "      num_steps=2000\n",
      "  )\n",
      "  sweep.run_sweep()\n",
      "\n",
      "  # Quick sweep (10-15 configs, ~1 hour)\n",
      "  quick_sweep = QuickSweep(...same args...)\n",
      "  quick_sweep.run_sweep()\n",
      "✓ Modules reloaded!\n"
     ]
    }
   ],
   "source": [
    "# Reload modules to pick up any code changes\n",
    "import importlib\n",
    "import sys\n",
    "\n",
    "if 'hyperparameter_sweep' in sys.modules:\n",
    "    importlib.reload(sys.modules['hyperparameter_sweep'])\n",
    "\n",
    "from hyperparameter_sweep import HyperparameterSweep, QuickSweep\n",
    "\n",
    "print(\"✓ Modules reloaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Training (No Apoptosis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training baseline model (2000 steps)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [01:01<00:00, 32.68it/s, loss=0.016]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Baseline training complete!\n",
      "Final loss: 0.0189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Train baseline model\n",
    "baseline_model = ApoptoticTransformer(\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    "    d_model=128,\n",
    "    n_heads=4,\n",
    "    n_layers=6,\n",
    "    max_seq_len=128\n",
    ").to(device)\n",
    "\n",
    "# Training\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    shakespeare_dataset, batch_size=64, shuffle=True, num_workers=0\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.AdamW(baseline_model.parameters(), lr=3e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "baseline_losses = []\n",
    "train_iter = iter(train_loader)\n",
    "\n",
    "from tqdm import tqdm\n",
    "print(\"Training baseline model (2000 steps)...\")\n",
    "pbar = tqdm(total=2000)\n",
    "\n",
    "for step in range(2000):\n",
    "    try:\n",
    "        x, y = next(train_iter)\n",
    "    except StopIteration:\n",
    "        train_iter = iter(train_loader)\n",
    "        x, y = next(train_iter)\n",
    "    \n",
    "    x, y = x.to(device), y.to(device)\n",
    "    \n",
    "    baseline_model.train()\n",
    "    logits = baseline_model(x)\n",
    "    loss = criterion(logits.reshape(-1, logits.size(-1)), y.reshape(-1))\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(baseline_model.parameters(), max_norm=1.0)\n",
    "    optimizer.step()\n",
    "    \n",
    "    baseline_losses.append(loss.item())\n",
    "    \n",
    "    if step % 100 == 0:\n",
    "        pbar.set_postfix({'loss': f'{loss.item():.3f}'})\n",
    "    pbar.update(1)\n",
    "\n",
    "pbar.close()\n",
    "\n",
    "baseline_final_loss = np.mean(baseline_losses[-100:])\n",
    "print(f\"\\n✓ Baseline training complete!\")\n",
    "print(f\"Final loss: {baseline_final_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Sweep\n",
    "\n",
    "Test multiple configurations to find optimal parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting hyperparameter sweep...\n",
      "Quick sweep - testing 13 configurations\n",
      "\n",
      "======================================================================\n",
      "HYPERPARAMETER SWEEP\n",
      "======================================================================\n",
      "Total experiments: 13\n",
      "Steps per experiment: 2000\n",
      "Estimated time: 65 minutes (~5 min per config)\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running experiments:   0%|                                                                                                                                    | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1/13] Testing: standard\n",
      "\n",
      "[Neuron Apoptosis @ step 500] blocks.0.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0001, 0.0008]\n",
      "\n",
      "[Neuron Apoptosis @ step 500] blocks.1.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0008]\n",
      "\n",
      "[Neuron Apoptosis @ step 500] blocks.2.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0007]\n",
      "\n",
      "[Neuron Apoptosis @ step 500] blocks.3.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0008]\n",
      "\n",
      "[Neuron Apoptosis @ step 500] blocks.4.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0007]\n",
      "\n",
      "[Neuron Apoptosis @ step 500] blocks.5.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0006]\n",
      "\n",
      "[Neuron Apoptosis @ step 1000] blocks.0.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0008]\n",
      "\n",
      "[Neuron Apoptosis @ step 1000] blocks.1.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0013]\n",
      "\n",
      "[Neuron Apoptosis @ step 1000] blocks.2.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0011]\n",
      "\n",
      "[Neuron Apoptosis @ step 1000] blocks.3.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0009]\n",
      "\n",
      "[Neuron Apoptosis @ step 1000] blocks.4.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0009]\n",
      "\n",
      "[Neuron Apoptosis @ step 1000] blocks.5.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0007]\n",
      "\n",
      "[Neuron Apoptosis @ step 1500] blocks.0.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0009]\n",
      "\n",
      "[Neuron Apoptosis @ step 1500] blocks.1.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0010]\n",
      "\n",
      "[Neuron Apoptosis @ step 1500] blocks.2.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0007]\n",
      "\n",
      "[Neuron Apoptosis @ step 1500] blocks.3.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0010]\n",
      "\n",
      "[Neuron Apoptosis @ step 1500] blocks.4.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0015]\n",
      "\n",
      "[Neuron Apoptosis @ step 1500] blocks.5.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0009]\n",
      "\n",
      "[Neuron Apoptosis @ step 2000] blocks.0.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0013]\n",
      "\n",
      "[Neuron Apoptosis @ step 2000] blocks.1.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0010]\n",
      "\n",
      "[Neuron Apoptosis @ step 2000] blocks.2.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0010]\n",
      "\n",
      "[Neuron Apoptosis @ step 2000] blocks.3.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0012]\n",
      "\n",
      "[Neuron Apoptosis @ step 2000] blocks.4.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0010]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running experiments:   8%|█████████▌                                                                                                                  | 1/13 [01:11<14:22, 71.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Neuron Apoptosis @ step 2000] blocks.5.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0015]\n",
      "  Final loss: 0.0207\n",
      "  Events: 24\n",
      "\n",
      "[2/13] Testing: standard\n",
      "\n",
      "[Neuron Apoptosis @ step 500] blocks.0.ffn.0\n",
      "  Pruning 76 neurons (bottom 15%)\n",
      "  Fitness range: [0.0001, 0.0007]\n",
      "\n",
      "[Neuron Apoptosis @ step 500] blocks.1.ffn.0\n",
      "  Pruning 76 neurons (bottom 15%)\n",
      "  Fitness range: [0.0001, 0.0009]\n",
      "\n",
      "[Neuron Apoptosis @ step 500] blocks.2.ffn.0\n",
      "  Pruning 76 neurons (bottom 15%)\n",
      "  Fitness range: [0.0000, 0.0006]\n",
      "\n",
      "[Neuron Apoptosis @ step 500] blocks.3.ffn.0\n",
      "  Pruning 76 neurons (bottom 15%)\n",
      "  Fitness range: [0.0000, 0.0007]\n",
      "\n",
      "[Neuron Apoptosis @ step 500] blocks.4.ffn.0\n",
      "  Pruning 76 neurons (bottom 15%)\n",
      "  Fitness range: [0.0000, 0.0006]\n",
      "\n",
      "[Neuron Apoptosis @ step 500] blocks.5.ffn.0\n",
      "  Pruning 76 neurons (bottom 15%)\n",
      "  Fitness range: [0.0000, 0.0011]\n",
      "\n",
      "[Neuron Apoptosis @ step 1000] blocks.0.ffn.0\n",
      "  Pruning 76 neurons (bottom 15%)\n",
      "  Fitness range: [0.0000, 0.0010]\n",
      "\n",
      "[Neuron Apoptosis @ step 1000] blocks.1.ffn.0\n",
      "  Pruning 76 neurons (bottom 15%)\n",
      "  Fitness range: [0.0000, 0.0018]\n",
      "\n",
      "[Neuron Apoptosis @ step 1000] blocks.2.ffn.0\n",
      "  Pruning 76 neurons (bottom 15%)\n",
      "  Fitness range: [0.0000, 0.0018]\n",
      "\n",
      "[Neuron Apoptosis @ step 1000] blocks.3.ffn.0\n",
      "  Pruning 76 neurons (bottom 15%)\n",
      "  Fitness range: [0.0000, 0.0014]\n",
      "\n",
      "[Neuron Apoptosis @ step 1000] blocks.4.ffn.0\n",
      "  Pruning 76 neurons (bottom 15%)\n",
      "  Fitness range: [0.0000, 0.0011]\n",
      "\n",
      "[Neuron Apoptosis @ step 1000] blocks.5.ffn.0\n",
      "  Pruning 76 neurons (bottom 15%)\n",
      "  Fitness range: [0.0000, 0.0015]\n",
      "\n",
      "[Neuron Apoptosis @ step 1500] blocks.0.ffn.0\n",
      "  Pruning 76 neurons (bottom 15%)\n",
      "  Fitness range: [0.0000, 0.0021]\n",
      "\n",
      "[Neuron Apoptosis @ step 1500] blocks.1.ffn.0\n",
      "  Pruning 76 neurons (bottom 15%)\n",
      "  Fitness range: [0.0000, 0.0014]\n",
      "\n",
      "[Neuron Apoptosis @ step 1500] blocks.2.ffn.0\n",
      "  Pruning 76 neurons (bottom 15%)\n",
      "  Fitness range: [0.0000, 0.0013]\n",
      "\n",
      "[Neuron Apoptosis @ step 1500] blocks.3.ffn.0\n",
      "  Pruning 76 neurons (bottom 15%)\n",
      "  Fitness range: [0.0000, 0.0012]\n",
      "\n",
      "[Neuron Apoptosis @ step 1500] blocks.4.ffn.0\n",
      "  Pruning 76 neurons (bottom 15%)\n",
      "  Fitness range: [0.0000, 0.0010]\n",
      "\n",
      "[Neuron Apoptosis @ step 1500] blocks.5.ffn.0\n",
      "  Pruning 76 neurons (bottom 15%)\n",
      "  Fitness range: [0.0000, 0.0013]\n",
      "\n",
      "[Neuron Apoptosis @ step 2000] blocks.0.ffn.0\n",
      "  Pruning 76 neurons (bottom 15%)\n",
      "  Fitness range: [0.0000, 0.0011]\n",
      "\n",
      "[Neuron Apoptosis @ step 2000] blocks.1.ffn.0\n",
      "  Pruning 76 neurons (bottom 15%)\n",
      "  Fitness range: [0.0000, 0.0009]\n",
      "\n",
      "[Neuron Apoptosis @ step 2000] blocks.2.ffn.0\n",
      "  Pruning 76 neurons (bottom 15%)\n",
      "  Fitness range: [0.0000, 0.0009]\n",
      "\n",
      "[Neuron Apoptosis @ step 2000] blocks.3.ffn.0\n",
      "  Pruning 76 neurons (bottom 15%)\n",
      "  Fitness range: [0.0000, 0.0008]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running experiments:  15%|███████████████████                                                                                                         | 2/13 [02:24<13:12, 72.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Neuron Apoptosis @ step 2000] blocks.4.ffn.0\n",
      "  Pruning 76 neurons (bottom 15%)\n",
      "  Fitness range: [0.0000, 0.0013]\n",
      "\n",
      "[Neuron Apoptosis @ step 2000] blocks.5.ffn.0\n",
      "  Pruning 76 neurons (bottom 15%)\n",
      "  Fitness range: [0.0000, 0.0016]\n",
      "  Final loss: 0.0200\n",
      "  Events: 24\n",
      "\n",
      "[3/13] Testing: functional\n",
      "\n",
      "[Neuron Apoptosis @ step 500] blocks.0.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0001, 0.0008]\n",
      "\n",
      "[Neuron Apoptosis @ step 500] blocks.1.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0001, 0.0008]\n",
      "\n",
      "[Neuron Apoptosis @ step 500] blocks.2.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0008]\n",
      "\n",
      "[Neuron Apoptosis @ step 500] blocks.3.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0006]\n",
      "\n",
      "[Neuron Apoptosis @ step 500] blocks.4.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0008]\n",
      "\n",
      "[Neuron Apoptosis @ step 500] blocks.5.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0011]\n",
      "\n",
      "[Neuron Apoptosis @ step 1000] blocks.0.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0010]\n",
      "\n",
      "[Neuron Apoptosis @ step 1000] blocks.1.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0010]\n",
      "\n",
      "[Neuron Apoptosis @ step 1000] blocks.2.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0006]\n",
      "\n",
      "[Neuron Apoptosis @ step 1000] blocks.3.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0005]\n",
      "\n",
      "[Neuron Apoptosis @ step 1000] blocks.4.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0007]\n",
      "\n",
      "[Neuron Apoptosis @ step 1000] blocks.5.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0010]\n",
      "\n",
      "[Neuron Apoptosis @ step 1500] blocks.0.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0007]\n",
      "\n",
      "[Neuron Apoptosis @ step 1500] blocks.1.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0007]\n",
      "\n",
      "[Neuron Apoptosis @ step 1500] blocks.2.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0008]\n",
      "\n",
      "[Neuron Apoptosis @ step 1500] blocks.3.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0005]\n",
      "\n",
      "[Neuron Apoptosis @ step 1500] blocks.4.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0007]\n",
      "\n",
      "[Neuron Apoptosis @ step 1500] blocks.5.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0011]\n",
      "\n",
      "[Neuron Apoptosis @ step 2000] blocks.0.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0005]\n",
      "\n",
      "[Neuron Apoptosis @ step 2000] blocks.1.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0008]\n",
      "\n",
      "[Neuron Apoptosis @ step 2000] blocks.2.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0006]\n",
      "\n",
      "[Neuron Apoptosis @ step 2000] blocks.3.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0005]\n",
      "\n",
      "[Neuron Apoptosis @ step 2000] blocks.4.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0006]\n",
      "\n",
      "[Neuron Apoptosis @ step 2000] blocks.5.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0009]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running experiments:  23%|████████████████████████████▍                                                                                              | 3/13 [09:13<37:43, 226.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Final loss: 0.0203\n",
      "  Events: 24\n",
      "\n",
      "[4/13] Testing: functional\n",
      "\n",
      "[Neuron Apoptosis @ step 500] blocks.0.ffn.0\n",
      "  Pruning 76 neurons (bottom 15%)\n",
      "  Fitness range: [0.0001, 0.0009]\n",
      "\n",
      "[Neuron Apoptosis @ step 500] blocks.1.ffn.0\n",
      "  Pruning 76 neurons (bottom 15%)\n",
      "  Fitness range: [0.0001, 0.0007]\n",
      "\n",
      "[Neuron Apoptosis @ step 500] blocks.2.ffn.0\n",
      "  Pruning 76 neurons (bottom 15%)\n",
      "  Fitness range: [0.0000, 0.0008]\n",
      "\n",
      "[Neuron Apoptosis @ step 500] blocks.3.ffn.0\n",
      "  Pruning 76 neurons (bottom 15%)\n",
      "  Fitness range: [0.0000, 0.0009]\n",
      "\n",
      "[Neuron Apoptosis @ step 500] blocks.4.ffn.0\n",
      "  Pruning 76 neurons (bottom 15%)\n",
      "  Fitness range: [0.0001, 0.0009]\n",
      "\n",
      "[Neuron Apoptosis @ step 500] blocks.5.ffn.0\n",
      "  Pruning 76 neurons (bottom 15%)\n",
      "  Fitness range: [0.0000, 0.0012]\n",
      "\n",
      "[Neuron Apoptosis @ step 1000] blocks.0.ffn.0\n",
      "  Pruning 76 neurons (bottom 15%)\n",
      "  Fitness range: [0.0000, 0.0006]\n",
      "\n",
      "[Neuron Apoptosis @ step 1000] blocks.1.ffn.0\n",
      "  Pruning 76 neurons (bottom 15%)\n",
      "  Fitness range: [0.0000, 0.0007]\n",
      "\n",
      "[Neuron Apoptosis @ step 1000] blocks.2.ffn.0\n",
      "  Pruning 76 neurons (bottom 15%)\n",
      "  Fitness range: [0.0000, 0.0006]\n",
      "\n",
      "[Neuron Apoptosis @ step 1000] blocks.3.ffn.0\n",
      "  Pruning 76 neurons (bottom 15%)\n",
      "  Fitness range: [0.0000, 0.0006]\n",
      "\n",
      "[Neuron Apoptosis @ step 1000] blocks.4.ffn.0\n",
      "  Pruning 76 neurons (bottom 15%)\n",
      "  Fitness range: [0.0000, 0.0010]\n",
      "\n",
      "[Neuron Apoptosis @ step 1000] blocks.5.ffn.0\n",
      "  Pruning 76 neurons (bottom 15%)\n",
      "  Fitness range: [0.0000, 0.0009]\n",
      "\n",
      "[Neuron Apoptosis @ step 1500] blocks.0.ffn.0\n",
      "  Pruning 76 neurons (bottom 15%)\n",
      "  Fitness range: [0.0000, 0.0007]\n",
      "\n",
      "[Neuron Apoptosis @ step 1500] blocks.1.ffn.0\n",
      "  Pruning 76 neurons (bottom 15%)\n",
      "  Fitness range: [0.0000, 0.0006]\n",
      "\n",
      "[Neuron Apoptosis @ step 1500] blocks.2.ffn.0\n",
      "  Pruning 76 neurons (bottom 15%)\n",
      "  Fitness range: [0.0000, 0.0007]\n",
      "\n",
      "[Neuron Apoptosis @ step 1500] blocks.3.ffn.0\n",
      "  Pruning 76 neurons (bottom 15%)\n",
      "  Fitness range: [0.0000, 0.0005]\n",
      "\n",
      "[Neuron Apoptosis @ step 1500] blocks.4.ffn.0\n",
      "  Pruning 76 neurons (bottom 15%)\n",
      "  Fitness range: [0.0000, 0.0007]\n",
      "\n",
      "[Neuron Apoptosis @ step 1500] blocks.5.ffn.0\n",
      "  Pruning 76 neurons (bottom 15%)\n",
      "  Fitness range: [0.0000, 0.0010]\n",
      "\n",
      "[Neuron Apoptosis @ step 2000] blocks.0.ffn.0\n",
      "  Pruning 76 neurons (bottom 15%)\n",
      "  Fitness range: [0.0000, 0.0009]\n",
      "\n",
      "[Neuron Apoptosis @ step 2000] blocks.1.ffn.0\n",
      "  Pruning 76 neurons (bottom 15%)\n",
      "  Fitness range: [0.0000, 0.0007]\n",
      "\n",
      "[Neuron Apoptosis @ step 2000] blocks.2.ffn.0\n",
      "  Pruning 76 neurons (bottom 15%)\n",
      "  Fitness range: [0.0000, 0.0006]\n",
      "\n",
      "[Neuron Apoptosis @ step 2000] blocks.3.ffn.0\n",
      "  Pruning 76 neurons (bottom 15%)\n",
      "  Fitness range: [0.0000, 0.0006]\n",
      "\n",
      "[Neuron Apoptosis @ step 2000] blocks.4.ffn.0\n",
      "  Pruning 76 neurons (bottom 15%)\n",
      "  Fitness range: [0.0000, 0.0010]\n",
      "\n",
      "[Neuron Apoptosis @ step 2000] blocks.5.ffn.0\n",
      "  Pruning 76 neurons (bottom 15%)\n",
      "  Fitness range: [0.0000, 0.0008]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running experiments:  31%|█████████████████████████████████████▊                                                                                     | 4/13 [18:07<52:09, 347.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Final loss: 0.0190\n",
      "  Events: 24\n",
      "\n",
      "[5/13] Testing: hybrid\n",
      "\n",
      "[Neuron Apoptosis @ step 400] blocks.0.ffn.0\n",
      "  Pruning 25 neurons (bottom 5%)\n",
      "  Fitness range: [0.0001, 0.0008]\n",
      "\n",
      "[Neuron Apoptosis @ step 400] blocks.1.ffn.0\n",
      "  Pruning 25 neurons (bottom 5%)\n",
      "  Fitness range: [0.0001, 0.0007]\n",
      "\n",
      "[Neuron Apoptosis @ step 400] blocks.2.ffn.0\n",
      "  Pruning 25 neurons (bottom 5%)\n",
      "  Fitness range: [0.0001, 0.0007]\n",
      "\n",
      "[Neuron Apoptosis @ step 400] blocks.3.ffn.0\n",
      "  Pruning 25 neurons (bottom 5%)\n",
      "  Fitness range: [0.0001, 0.0008]\n",
      "\n",
      "[Neuron Apoptosis @ step 400] blocks.4.ffn.0\n",
      "  Pruning 25 neurons (bottom 5%)\n",
      "  Fitness range: [0.0001, 0.0011]\n",
      "\n",
      "[Neuron Apoptosis @ step 400] blocks.5.ffn.0\n",
      "  Pruning 25 neurons (bottom 5%)\n",
      "  Fitness range: [0.0001, 0.0011]\n",
      "\n",
      "[Neuron Apoptosis @ step 800] blocks.0.ffn.0\n",
      "  Pruning 25 neurons (bottom 5%)\n",
      "  Fitness range: [0.0000, 0.0011]\n",
      "\n",
      "[Neuron Apoptosis @ step 800] blocks.1.ffn.0\n",
      "  Pruning 25 neurons (bottom 5%)\n",
      "  Fitness range: [0.0000, 0.0012]\n",
      "\n",
      "[Neuron Apoptosis @ step 800] blocks.2.ffn.0\n",
      "  Pruning 25 neurons (bottom 5%)\n",
      "  Fitness range: [0.0000, 0.0009]\n",
      "\n",
      "[Neuron Apoptosis @ step 800] blocks.3.ffn.0\n",
      "  Pruning 25 neurons (bottom 5%)\n",
      "  Fitness range: [0.0000, 0.0009]\n",
      "\n",
      "[Neuron Apoptosis @ step 800] blocks.4.ffn.0\n",
      "  Pruning 25 neurons (bottom 5%)\n",
      "  Fitness range: [0.0000, 0.0012]\n",
      "\n",
      "[Neuron Apoptosis @ step 800] blocks.5.ffn.0\n",
      "  Pruning 25 neurons (bottom 5%)\n",
      "  Fitness range: [0.0000, 0.0012]\n",
      "\n",
      "[Neuron Apoptosis @ step 1200] blocks.0.ffn.0\n",
      "  Pruning 25 neurons (bottom 5%)\n",
      "  Fitness range: [0.0000, 0.0009]\n",
      "\n",
      "[Neuron Apoptosis @ step 1200] blocks.1.ffn.0\n",
      "  Pruning 25 neurons (bottom 5%)\n",
      "  Fitness range: [0.0000, 0.0007]\n",
      "\n",
      "[Neuron Apoptosis @ step 1200] blocks.2.ffn.0\n",
      "  Pruning 25 neurons (bottom 5%)\n",
      "  Fitness range: [0.0000, 0.0008]\n",
      "\n",
      "[Neuron Apoptosis @ step 1200] blocks.3.ffn.0\n",
      "  Pruning 25 neurons (bottom 5%)\n",
      "  Fitness range: [0.0000, 0.0007]\n",
      "\n",
      "[Neuron Apoptosis @ step 1200] blocks.4.ffn.0\n",
      "  Pruning 25 neurons (bottom 5%)\n",
      "  Fitness range: [0.0000, 0.0008]\n",
      "\n",
      "[Neuron Apoptosis @ step 1200] blocks.5.ffn.0\n",
      "  Pruning 25 neurons (bottom 5%)\n",
      "  Fitness range: [0.0000, 0.0015]\n",
      "\n",
      "[Neuron Apoptosis @ step 1600] blocks.0.ffn.0\n",
      "  Pruning 25 neurons (bottom 5%)\n",
      "  Fitness range: [0.0000, 0.0008]\n",
      "\n",
      "[Neuron Apoptosis @ step 1600] blocks.1.ffn.0\n",
      "  Pruning 25 neurons (bottom 5%)\n",
      "  Fitness range: [0.0000, 0.0006]\n",
      "\n",
      "[Neuron Apoptosis @ step 1600] blocks.2.ffn.0\n",
      "  Pruning 25 neurons (bottom 5%)\n",
      "  Fitness range: [0.0000, 0.0011]\n",
      "\n",
      "[Neuron Apoptosis @ step 1600] blocks.3.ffn.0\n",
      "  Pruning 25 neurons (bottom 5%)\n",
      "  Fitness range: [0.0000, 0.0010]\n",
      "\n",
      "[Neuron Apoptosis @ step 1600] blocks.4.ffn.0\n",
      "  Pruning 25 neurons (bottom 5%)\n",
      "  Fitness range: [0.0000, 0.0009]\n",
      "\n",
      "[Neuron Apoptosis @ step 1600] blocks.5.ffn.0\n",
      "  Pruning 25 neurons (bottom 5%)\n",
      "  Fitness range: [0.0000, 0.0014]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running experiments:  38%|███████████████████████████████████████████████▎                                                                           | 5/13 [19:19<33:05, 248.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Neuron Apoptosis @ step 2000] blocks.0.ffn.0\n",
      "  Pruning 25 neurons (bottom 5%)\n",
      "  Fitness range: [0.0000, 0.0012]\n",
      "\n",
      "[Neuron Apoptosis @ step 2000] blocks.1.ffn.0\n",
      "  Pruning 25 neurons (bottom 5%)\n",
      "  Fitness range: [0.0000, 0.0009]\n",
      "\n",
      "[Neuron Apoptosis @ step 2000] blocks.2.ffn.0\n",
      "  Pruning 25 neurons (bottom 5%)\n",
      "  Fitness range: [0.0000, 0.0008]\n",
      "\n",
      "[Neuron Apoptosis @ step 2000] blocks.3.ffn.0\n",
      "  Pruning 25 neurons (bottom 5%)\n",
      "  Fitness range: [0.0000, 0.0008]\n",
      "\n",
      "[Neuron Apoptosis @ step 2000] blocks.4.ffn.0\n",
      "  Pruning 25 neurons (bottom 5%)\n",
      "  Fitness range: [0.0000, 0.0009]\n",
      "\n",
      "[Neuron Apoptosis @ step 2000] blocks.5.ffn.0\n",
      "  Pruning 25 neurons (bottom 5%)\n",
      "  Fitness range: [0.0000, 0.0027]\n",
      "  Final loss: 0.0205\n",
      "  Events: 30\n",
      "\n",
      "[6/13] Testing: hybrid\n",
      "\n",
      "[Neuron Apoptosis @ step 500] blocks.0.ffn.0\n",
      "  Pruning 25 neurons (bottom 5%)\n",
      "  Fitness range: [0.0001, 0.0008]\n",
      "\n",
      "[Neuron Apoptosis @ step 500] blocks.1.ffn.0\n",
      "  Pruning 25 neurons (bottom 5%)\n",
      "  Fitness range: [0.0001, 0.0007]\n",
      "\n",
      "[Neuron Apoptosis @ step 500] blocks.2.ffn.0\n",
      "  Pruning 25 neurons (bottom 5%)\n",
      "  Fitness range: [0.0000, 0.0011]\n",
      "\n",
      "[Neuron Apoptosis @ step 500] blocks.3.ffn.0\n",
      "  Pruning 25 neurons (bottom 5%)\n",
      "  Fitness range: [0.0000, 0.0006]\n",
      "\n",
      "[Neuron Apoptosis @ step 500] blocks.4.ffn.0\n",
      "  Pruning 25 neurons (bottom 5%)\n",
      "  Fitness range: [0.0000, 0.0010]\n",
      "\n",
      "[Neuron Apoptosis @ step 500] blocks.5.ffn.0\n",
      "  Pruning 25 neurons (bottom 5%)\n",
      "  Fitness range: [0.0000, 0.0006]\n",
      "\n",
      "[Neuron Apoptosis @ step 1000] blocks.0.ffn.0\n",
      "  Pruning 25 neurons (bottom 5%)\n",
      "  Fitness range: [0.0000, 0.0007]\n",
      "\n",
      "[Neuron Apoptosis @ step 1000] blocks.1.ffn.0\n",
      "  Pruning 25 neurons (bottom 5%)\n",
      "  Fitness range: [0.0000, 0.0010]\n",
      "\n",
      "[Neuron Apoptosis @ step 1000] blocks.2.ffn.0\n",
      "  Pruning 25 neurons (bottom 5%)\n",
      "  Fitness range: [0.0000, 0.0008]\n",
      "\n",
      "[Neuron Apoptosis @ step 1000] blocks.3.ffn.0\n",
      "  Pruning 25 neurons (bottom 5%)\n",
      "  Fitness range: [0.0000, 0.0010]\n",
      "\n",
      "[Neuron Apoptosis @ step 1000] blocks.4.ffn.0\n",
      "  Pruning 25 neurons (bottom 5%)\n",
      "  Fitness range: [0.0000, 0.0010]\n",
      "\n",
      "[Neuron Apoptosis @ step 1000] blocks.5.ffn.0\n",
      "  Pruning 25 neurons (bottom 5%)\n",
      "  Fitness range: [0.0000, 0.0016]\n",
      "\n",
      "[Neuron Apoptosis @ step 1500] blocks.0.ffn.0\n",
      "  Pruning 25 neurons (bottom 5%)\n",
      "  Fitness range: [0.0000, 0.0009]\n",
      "\n",
      "[Neuron Apoptosis @ step 1500] blocks.1.ffn.0\n",
      "  Pruning 25 neurons (bottom 5%)\n",
      "  Fitness range: [0.0000, 0.0009]\n",
      "\n",
      "[Neuron Apoptosis @ step 1500] blocks.2.ffn.0\n",
      "  Pruning 25 neurons (bottom 5%)\n",
      "  Fitness range: [0.0000, 0.0010]\n",
      "\n",
      "[Neuron Apoptosis @ step 1500] blocks.3.ffn.0\n",
      "  Pruning 25 neurons (bottom 5%)\n",
      "  Fitness range: [0.0000, 0.0007]\n",
      "\n",
      "[Neuron Apoptosis @ step 1500] blocks.4.ffn.0\n",
      "  Pruning 25 neurons (bottom 5%)\n",
      "  Fitness range: [0.0000, 0.0016]\n",
      "\n",
      "[Neuron Apoptosis @ step 1500] blocks.5.ffn.0\n",
      "  Pruning 25 neurons (bottom 5%)\n",
      "  Fitness range: [0.0000, 0.0019]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running experiments:  46%|████████████████████████████████████████████████████████▊                                                                  | 6/13 [20:32<22:01, 188.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Neuron Apoptosis @ step 2000] blocks.0.ffn.0\n",
      "  Pruning 25 neurons (bottom 5%)\n",
      "  Fitness range: [0.0000, 0.0010]\n",
      "\n",
      "[Neuron Apoptosis @ step 2000] blocks.1.ffn.0\n",
      "  Pruning 25 neurons (bottom 5%)\n",
      "  Fitness range: [0.0000, 0.0019]\n",
      "\n",
      "[Neuron Apoptosis @ step 2000] blocks.2.ffn.0\n",
      "  Pruning 25 neurons (bottom 5%)\n",
      "  Fitness range: [0.0000, 0.0014]\n",
      "\n",
      "[Neuron Apoptosis @ step 2000] blocks.3.ffn.0\n",
      "  Pruning 25 neurons (bottom 5%)\n",
      "  Fitness range: [0.0000, 0.0017]\n",
      "\n",
      "[Neuron Apoptosis @ step 2000] blocks.4.ffn.0\n",
      "  Pruning 25 neurons (bottom 5%)\n",
      "  Fitness range: [0.0000, 0.0010]\n",
      "\n",
      "[Neuron Apoptosis @ step 2000] blocks.5.ffn.0\n",
      "  Pruning 25 neurons (bottom 5%)\n",
      "  Fitness range: [0.0000, 0.0022]\n",
      "  Final loss: 0.0203\n",
      "  Events: 24\n",
      "\n",
      "[7/13] Testing: hybrid\n",
      "\n",
      "[Neuron Apoptosis @ step 600] blocks.0.ffn.0\n",
      "  Pruning 25 neurons (bottom 5%)\n",
      "  Fitness range: [0.0001, 0.0005]\n",
      "\n",
      "[Neuron Apoptosis @ step 600] blocks.1.ffn.0\n",
      "  Pruning 25 neurons (bottom 5%)\n",
      "  Fitness range: [0.0000, 0.0007]\n",
      "\n",
      "[Neuron Apoptosis @ step 600] blocks.2.ffn.0\n",
      "  Pruning 25 neurons (bottom 5%)\n",
      "  Fitness range: [0.0000, 0.0005]\n",
      "\n",
      "[Neuron Apoptosis @ step 600] blocks.3.ffn.0\n",
      "  Pruning 25 neurons (bottom 5%)\n",
      "  Fitness range: [0.0000, 0.0007]\n",
      "\n",
      "[Neuron Apoptosis @ step 600] blocks.4.ffn.0\n",
      "  Pruning 25 neurons (bottom 5%)\n",
      "  Fitness range: [0.0000, 0.0006]\n",
      "\n",
      "[Neuron Apoptosis @ step 600] blocks.5.ffn.0\n",
      "  Pruning 25 neurons (bottom 5%)\n",
      "  Fitness range: [0.0000, 0.0005]\n",
      "\n",
      "[Neuron Apoptosis @ step 1200] blocks.0.ffn.0\n",
      "  Pruning 25 neurons (bottom 5%)\n",
      "  Fitness range: [0.0000, 0.0009]\n",
      "\n",
      "[Neuron Apoptosis @ step 1200] blocks.1.ffn.0\n",
      "  Pruning 25 neurons (bottom 5%)\n",
      "  Fitness range: [0.0000, 0.0006]\n",
      "\n",
      "[Neuron Apoptosis @ step 1200] blocks.2.ffn.0\n",
      "  Pruning 25 neurons (bottom 5%)\n",
      "  Fitness range: [0.0000, 0.0020]\n",
      "\n",
      "[Neuron Apoptosis @ step 1200] blocks.3.ffn.0\n",
      "  Pruning 25 neurons (bottom 5%)\n",
      "  Fitness range: [0.0000, 0.0010]\n",
      "\n",
      "[Neuron Apoptosis @ step 1200] blocks.4.ffn.0\n",
      "  Pruning 25 neurons (bottom 5%)\n",
      "  Fitness range: [0.0000, 0.0010]\n",
      "\n",
      "[Neuron Apoptosis @ step 1200] blocks.5.ffn.0\n",
      "  Pruning 25 neurons (bottom 5%)\n",
      "  Fitness range: [0.0000, 0.0008]\n",
      "\n",
      "[Neuron Apoptosis @ step 1800] blocks.0.ffn.0\n",
      "  Pruning 25 neurons (bottom 5%)\n",
      "  Fitness range: [0.0000, 0.0008]\n",
      "\n",
      "[Neuron Apoptosis @ step 1800] blocks.1.ffn.0\n",
      "  Pruning 25 neurons (bottom 5%)\n",
      "  Fitness range: [0.0000, 0.0006]\n",
      "\n",
      "[Neuron Apoptosis @ step 1800] blocks.2.ffn.0\n",
      "  Pruning 25 neurons (bottom 5%)\n",
      "  Fitness range: [0.0000, 0.0008]\n",
      "\n",
      "[Neuron Apoptosis @ step 1800] blocks.3.ffn.0\n",
      "  Pruning 25 neurons (bottom 5%)\n",
      "  Fitness range: [0.0000, 0.0008]\n",
      "\n",
      "[Neuron Apoptosis @ step 1800] blocks.4.ffn.0\n",
      "  Pruning 25 neurons (bottom 5%)\n",
      "  Fitness range: [0.0000, 0.0010]\n",
      "\n",
      "[Neuron Apoptosis @ step 1800] blocks.5.ffn.0\n",
      "  Pruning 25 neurons (bottom 5%)\n",
      "  Fitness range: [0.0000, 0.0011]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running experiments:  54%|██████████████████████████████████████████████████████████████████▏                                                        | 7/13 [21:59<15:32, 155.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Final loss: 0.0206\n",
      "  Events: 18\n",
      "\n",
      "[8/13] Testing: hybrid\n",
      "\n",
      "[Neuron Apoptosis @ step 400] blocks.0.ffn.0\n",
      "  Pruning 40 neurons (bottom 8%)\n",
      "  Fitness range: [0.0002, 0.0012]\n",
      "\n",
      "[Neuron Apoptosis @ step 400] blocks.1.ffn.0\n",
      "  Pruning 40 neurons (bottom 8%)\n",
      "  Fitness range: [0.0001, 0.0010]\n",
      "\n",
      "[Neuron Apoptosis @ step 400] blocks.2.ffn.0\n",
      "  Pruning 40 neurons (bottom 8%)\n",
      "  Fitness range: [0.0001, 0.0018]\n",
      "\n",
      "[Neuron Apoptosis @ step 400] blocks.3.ffn.0\n",
      "  Pruning 40 neurons (bottom 8%)\n",
      "  Fitness range: [0.0001, 0.0019]\n",
      "\n",
      "[Neuron Apoptosis @ step 400] blocks.4.ffn.0\n",
      "  Pruning 40 neurons (bottom 8%)\n",
      "  Fitness range: [0.0001, 0.0012]\n",
      "\n",
      "[Neuron Apoptosis @ step 400] blocks.5.ffn.0\n",
      "  Pruning 40 neurons (bottom 8%)\n",
      "  Fitness range: [0.0001, 0.0015]\n",
      "\n",
      "[Neuron Apoptosis @ step 800] blocks.0.ffn.0\n",
      "  Pruning 40 neurons (bottom 8%)\n",
      "  Fitness range: [0.0000, 0.0010]\n",
      "\n",
      "[Neuron Apoptosis @ step 800] blocks.1.ffn.0\n",
      "  Pruning 40 neurons (bottom 8%)\n",
      "  Fitness range: [0.0000, 0.0013]\n",
      "\n",
      "[Neuron Apoptosis @ step 800] blocks.2.ffn.0\n",
      "  Pruning 40 neurons (bottom 8%)\n",
      "  Fitness range: [0.0000, 0.0015]\n",
      "\n",
      "[Neuron Apoptosis @ step 800] blocks.3.ffn.0\n",
      "  Pruning 40 neurons (bottom 8%)\n",
      "  Fitness range: [0.0000, 0.0011]\n",
      "\n",
      "[Neuron Apoptosis @ step 800] blocks.4.ffn.0\n",
      "  Pruning 40 neurons (bottom 8%)\n",
      "  Fitness range: [0.0000, 0.0011]\n",
      "\n",
      "[Neuron Apoptosis @ step 800] blocks.5.ffn.0\n",
      "  Pruning 40 neurons (bottom 8%)\n",
      "  Fitness range: [0.0000, 0.0012]\n",
      "\n",
      "[Neuron Apoptosis @ step 1200] blocks.0.ffn.0\n",
      "  Pruning 40 neurons (bottom 8%)\n",
      "  Fitness range: [0.0000, 0.0010]\n",
      "\n",
      "[Neuron Apoptosis @ step 1200] blocks.1.ffn.0\n",
      "  Pruning 40 neurons (bottom 8%)\n",
      "  Fitness range: [0.0000, 0.0014]\n",
      "\n",
      "[Neuron Apoptosis @ step 1200] blocks.2.ffn.0\n",
      "  Pruning 40 neurons (bottom 8%)\n",
      "  Fitness range: [0.0000, 0.0010]\n",
      "\n",
      "[Neuron Apoptosis @ step 1200] blocks.3.ffn.0\n",
      "  Pruning 40 neurons (bottom 8%)\n",
      "  Fitness range: [0.0000, 0.0011]\n",
      "\n",
      "[Neuron Apoptosis @ step 1200] blocks.4.ffn.0\n",
      "  Pruning 40 neurons (bottom 8%)\n",
      "  Fitness range: [0.0000, 0.0011]\n",
      "\n",
      "[Neuron Apoptosis @ step 1200] blocks.5.ffn.0\n",
      "  Pruning 40 neurons (bottom 8%)\n",
      "  Fitness range: [0.0000, 0.0023]\n",
      "\n",
      "[Neuron Apoptosis @ step 1600] blocks.0.ffn.0\n",
      "  Pruning 40 neurons (bottom 8%)\n",
      "  Fitness range: [0.0000, 0.0011]\n",
      "\n",
      "[Neuron Apoptosis @ step 1600] blocks.1.ffn.0\n",
      "  Pruning 40 neurons (bottom 8%)\n",
      "  Fitness range: [0.0000, 0.0018]\n",
      "\n",
      "[Neuron Apoptosis @ step 1600] blocks.2.ffn.0\n",
      "  Pruning 40 neurons (bottom 8%)\n",
      "  Fitness range: [0.0000, 0.0015]\n",
      "\n",
      "[Neuron Apoptosis @ step 1600] blocks.3.ffn.0\n",
      "  Pruning 40 neurons (bottom 8%)\n",
      "  Fitness range: [0.0000, 0.0014]\n",
      "\n",
      "[Neuron Apoptosis @ step 1600] blocks.4.ffn.0\n",
      "  Pruning 40 neurons (bottom 8%)\n",
      "  Fitness range: [0.0000, 0.0018]\n",
      "\n",
      "[Neuron Apoptosis @ step 1600] blocks.5.ffn.0\n",
      "  Pruning 40 neurons (bottom 8%)\n",
      "  Fitness range: [0.0000, 0.0012]\n",
      "\n",
      "[Neuron Apoptosis @ step 2000] blocks.0.ffn.0\n",
      "  Pruning 40 neurons (bottom 8%)\n",
      "  Fitness range: [0.0000, 0.0007]\n",
      "\n",
      "[Neuron Apoptosis @ step 2000] blocks.1.ffn.0\n",
      "  Pruning 40 neurons (bottom 8%)\n",
      "  Fitness range: [0.0000, 0.0012]\n",
      "\n",
      "[Neuron Apoptosis @ step 2000] blocks.2.ffn.0\n",
      "  Pruning 40 neurons (bottom 8%)\n",
      "  Fitness range: [0.0000, 0.0006]\n",
      "\n",
      "[Neuron Apoptosis @ step 2000] blocks.3.ffn.0\n",
      "  Pruning 40 neurons (bottom 8%)\n",
      "  Fitness range: [0.0000, 0.0007]\n",
      "\n",
      "[Neuron Apoptosis @ step 2000] blocks.4.ffn.0\n",
      "  Pruning 40 neurons (bottom 8%)\n",
      "  Fitness range: [0.0000, 0.0011]\n",
      "\n",
      "[Neuron Apoptosis @ step 2000] blocks.5.ffn.0\n",
      "  Pruning 40 neurons (bottom 8%)\n",
      "  Fitness range: [0.0000, 0.0012]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running experiments:  62%|███████████████████████████████████████████████████████████████████████████▋                                               | 8/13 [23:14<10:48, 129.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Final loss: 0.0208\n",
      "  Events: 30\n",
      "\n",
      "[9/13] Testing: hybrid\n",
      "\n",
      "[Neuron Apoptosis @ step 500] blocks.0.ffn.0\n",
      "  Pruning 40 neurons (bottom 8%)\n",
      "  Fitness range: [0.0002, 0.0009]\n",
      "\n",
      "[Neuron Apoptosis @ step 500] blocks.1.ffn.0\n",
      "  Pruning 40 neurons (bottom 8%)\n",
      "  Fitness range: [0.0001, 0.0008]\n",
      "\n",
      "[Neuron Apoptosis @ step 500] blocks.2.ffn.0\n",
      "  Pruning 40 neurons (bottom 8%)\n",
      "  Fitness range: [0.0000, 0.0009]\n",
      "\n",
      "[Neuron Apoptosis @ step 500] blocks.3.ffn.0\n",
      "  Pruning 40 neurons (bottom 8%)\n",
      "  Fitness range: [0.0000, 0.0012]\n",
      "\n",
      "[Neuron Apoptosis @ step 500] blocks.4.ffn.0\n",
      "  Pruning 40 neurons (bottom 8%)\n",
      "  Fitness range: [0.0000, 0.0009]\n",
      "\n",
      "[Neuron Apoptosis @ step 500] blocks.5.ffn.0\n",
      "  Pruning 40 neurons (bottom 8%)\n",
      "  Fitness range: [0.0000, 0.0012]\n",
      "\n",
      "[Neuron Apoptosis @ step 1000] blocks.0.ffn.0\n",
      "  Pruning 40 neurons (bottom 8%)\n",
      "  Fitness range: [0.0000, 0.0012]\n",
      "\n",
      "[Neuron Apoptosis @ step 1000] blocks.1.ffn.0\n",
      "  Pruning 40 neurons (bottom 8%)\n",
      "  Fitness range: [0.0000, 0.0009]\n",
      "\n",
      "[Neuron Apoptosis @ step 1000] blocks.2.ffn.0\n",
      "  Pruning 40 neurons (bottom 8%)\n",
      "  Fitness range: [0.0000, 0.0010]\n",
      "\n",
      "[Neuron Apoptosis @ step 1000] blocks.3.ffn.0\n",
      "  Pruning 40 neurons (bottom 8%)\n",
      "  Fitness range: [0.0000, 0.0008]\n",
      "\n",
      "[Neuron Apoptosis @ step 1000] blocks.4.ffn.0\n",
      "  Pruning 40 neurons (bottom 8%)\n",
      "  Fitness range: [0.0000, 0.0009]\n",
      "\n",
      "[Neuron Apoptosis @ step 1000] blocks.5.ffn.0\n",
      "  Pruning 40 neurons (bottom 8%)\n",
      "  Fitness range: [0.0000, 0.0009]\n",
      "\n",
      "[Neuron Apoptosis @ step 1500] blocks.0.ffn.0\n",
      "  Pruning 40 neurons (bottom 8%)\n",
      "  Fitness range: [0.0000, 0.0014]\n",
      "\n",
      "[Neuron Apoptosis @ step 1500] blocks.1.ffn.0\n",
      "  Pruning 40 neurons (bottom 8%)\n",
      "  Fitness range: [0.0000, 0.0010]\n",
      "\n",
      "[Neuron Apoptosis @ step 1500] blocks.2.ffn.0\n",
      "  Pruning 40 neurons (bottom 8%)\n",
      "  Fitness range: [0.0000, 0.0011]\n",
      "\n",
      "[Neuron Apoptosis @ step 1500] blocks.3.ffn.0\n",
      "  Pruning 40 neurons (bottom 8%)\n",
      "  Fitness range: [0.0000, 0.0009]\n",
      "\n",
      "[Neuron Apoptosis @ step 1500] blocks.4.ffn.0\n",
      "  Pruning 40 neurons (bottom 8%)\n",
      "  Fitness range: [0.0000, 0.0010]\n",
      "\n",
      "[Neuron Apoptosis @ step 1500] blocks.5.ffn.0\n",
      "  Pruning 40 neurons (bottom 8%)\n",
      "  Fitness range: [0.0000, 0.0013]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running experiments:  69%|█████████████████████████████████████████████████████████████████████████████████████▏                                     | 9/13 [24:25<07:25, 111.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Neuron Apoptosis @ step 2000] blocks.0.ffn.0\n",
      "  Pruning 40 neurons (bottom 8%)\n",
      "  Fitness range: [0.0000, 0.0010]\n",
      "\n",
      "[Neuron Apoptosis @ step 2000] blocks.1.ffn.0\n",
      "  Pruning 40 neurons (bottom 8%)\n",
      "  Fitness range: [0.0000, 0.0017]\n",
      "\n",
      "[Neuron Apoptosis @ step 2000] blocks.2.ffn.0\n",
      "  Pruning 40 neurons (bottom 8%)\n",
      "  Fitness range: [0.0000, 0.0011]\n",
      "\n",
      "[Neuron Apoptosis @ step 2000] blocks.3.ffn.0\n",
      "  Pruning 40 neurons (bottom 8%)\n",
      "  Fitness range: [0.0000, 0.0009]\n",
      "\n",
      "[Neuron Apoptosis @ step 2000] blocks.4.ffn.0\n",
      "  Pruning 40 neurons (bottom 8%)\n",
      "  Fitness range: [0.0000, 0.0014]\n",
      "\n",
      "[Neuron Apoptosis @ step 2000] blocks.5.ffn.0\n",
      "  Pruning 40 neurons (bottom 8%)\n",
      "  Fitness range: [0.0000, 0.0015]\n",
      "  Final loss: 0.0193\n",
      "  Events: 24\n",
      "\n",
      "[10/13] Testing: hybrid\n",
      "\n",
      "[Neuron Apoptosis @ step 600] blocks.0.ffn.0\n",
      "  Pruning 40 neurons (bottom 8%)\n",
      "  Fitness range: [0.0001, 0.0008]\n",
      "\n",
      "[Neuron Apoptosis @ step 600] blocks.1.ffn.0\n",
      "  Pruning 40 neurons (bottom 8%)\n",
      "  Fitness range: [0.0000, 0.0006]\n",
      "\n",
      "[Neuron Apoptosis @ step 600] blocks.2.ffn.0\n",
      "  Pruning 40 neurons (bottom 8%)\n",
      "  Fitness range: [0.0000, 0.0006]\n",
      "\n",
      "[Neuron Apoptosis @ step 600] blocks.3.ffn.0\n",
      "  Pruning 40 neurons (bottom 8%)\n",
      "  Fitness range: [0.0000, 0.0006]\n",
      "\n",
      "[Neuron Apoptosis @ step 600] blocks.4.ffn.0\n",
      "  Pruning 40 neurons (bottom 8%)\n",
      "  Fitness range: [0.0000, 0.0007]\n",
      "\n",
      "[Neuron Apoptosis @ step 600] blocks.5.ffn.0\n",
      "  Pruning 40 neurons (bottom 8%)\n",
      "  Fitness range: [0.0000, 0.0008]\n",
      "\n",
      "[Neuron Apoptosis @ step 1200] blocks.0.ffn.0\n",
      "  Pruning 40 neurons (bottom 8%)\n",
      "  Fitness range: [0.0000, 0.0013]\n",
      "\n",
      "[Neuron Apoptosis @ step 1200] blocks.1.ffn.0\n",
      "  Pruning 40 neurons (bottom 8%)\n",
      "  Fitness range: [0.0000, 0.0009]\n",
      "\n",
      "[Neuron Apoptosis @ step 1200] blocks.2.ffn.0\n",
      "  Pruning 40 neurons (bottom 8%)\n",
      "  Fitness range: [0.0000, 0.0011]\n",
      "\n",
      "[Neuron Apoptosis @ step 1200] blocks.3.ffn.0\n",
      "  Pruning 40 neurons (bottom 8%)\n",
      "  Fitness range: [0.0000, 0.0009]\n",
      "\n",
      "[Neuron Apoptosis @ step 1200] blocks.4.ffn.0\n",
      "  Pruning 40 neurons (bottom 8%)\n",
      "  Fitness range: [0.0000, 0.0018]\n",
      "\n",
      "[Neuron Apoptosis @ step 1200] blocks.5.ffn.0\n",
      "  Pruning 40 neurons (bottom 8%)\n",
      "  Fitness range: [0.0000, 0.0012]\n",
      "\n",
      "[Neuron Apoptosis @ step 1800] blocks.0.ffn.0\n",
      "  Pruning 40 neurons (bottom 8%)\n",
      "  Fitness range: [0.0000, 0.0010]\n",
      "\n",
      "[Neuron Apoptosis @ step 1800] blocks.1.ffn.0\n",
      "  Pruning 40 neurons (bottom 8%)\n",
      "  Fitness range: [0.0000, 0.0008]\n",
      "\n",
      "[Neuron Apoptosis @ step 1800] blocks.2.ffn.0\n",
      "  Pruning 40 neurons (bottom 8%)\n",
      "  Fitness range: [0.0000, 0.0008]\n",
      "\n",
      "[Neuron Apoptosis @ step 1800] blocks.3.ffn.0\n",
      "  Pruning 40 neurons (bottom 8%)\n",
      "  Fitness range: [0.0000, 0.0009]\n",
      "\n",
      "[Neuron Apoptosis @ step 1800] blocks.4.ffn.0\n",
      "  Pruning 40 neurons (bottom 8%)\n",
      "  Fitness range: [0.0000, 0.0010]\n",
      "\n",
      "[Neuron Apoptosis @ step 1800] blocks.5.ffn.0\n",
      "  Pruning 40 neurons (bottom 8%)\n",
      "  Fitness range: [0.0000, 0.0018]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running experiments:  77%|██████████████████████████████████████████████████████████████████████████████████████████████▌                            | 10/13 [25:36<04:57, 99.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Final loss: 0.0208\n",
      "  Events: 18\n",
      "\n",
      "[11/13] Testing: hybrid\n",
      "\n",
      "[Neuron Apoptosis @ step 400] blocks.0.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0002, 0.0011]\n",
      "\n",
      "[Neuron Apoptosis @ step 400] blocks.1.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0001, 0.0012]\n",
      "\n",
      "[Neuron Apoptosis @ step 400] blocks.2.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0001, 0.0020]\n",
      "\n",
      "[Neuron Apoptosis @ step 400] blocks.3.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0001, 0.0015]\n",
      "\n",
      "[Neuron Apoptosis @ step 400] blocks.4.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0001, 0.0014]\n",
      "\n",
      "[Neuron Apoptosis @ step 400] blocks.5.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0001, 0.0016]\n",
      "\n",
      "[Neuron Apoptosis @ step 800] blocks.0.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0010]\n",
      "\n",
      "[Neuron Apoptosis @ step 800] blocks.1.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0009]\n",
      "\n",
      "[Neuron Apoptosis @ step 800] blocks.2.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0010]\n",
      "\n",
      "[Neuron Apoptosis @ step 800] blocks.3.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0011]\n",
      "\n",
      "[Neuron Apoptosis @ step 800] blocks.4.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0013]\n",
      "\n",
      "[Neuron Apoptosis @ step 800] blocks.5.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0015]\n",
      "\n",
      "[Neuron Apoptosis @ step 1200] blocks.0.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0013]\n",
      "\n",
      "[Neuron Apoptosis @ step 1200] blocks.1.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0010]\n",
      "\n",
      "[Neuron Apoptosis @ step 1200] blocks.2.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0010]\n",
      "\n",
      "[Neuron Apoptosis @ step 1200] blocks.3.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0013]\n",
      "\n",
      "[Neuron Apoptosis @ step 1200] blocks.4.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0012]\n",
      "\n",
      "[Neuron Apoptosis @ step 1200] blocks.5.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0014]\n",
      "\n",
      "[Neuron Apoptosis @ step 1600] blocks.0.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0010]\n",
      "\n",
      "[Neuron Apoptosis @ step 1600] blocks.1.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0009]\n",
      "\n",
      "[Neuron Apoptosis @ step 1600] blocks.2.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0012]\n",
      "\n",
      "[Neuron Apoptosis @ step 1600] blocks.3.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0011]\n",
      "\n",
      "[Neuron Apoptosis @ step 1600] blocks.4.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0013]\n",
      "\n",
      "[Neuron Apoptosis @ step 1600] blocks.5.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0010]\n",
      "\n",
      "[Neuron Apoptosis @ step 2000] blocks.0.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0010]\n",
      "\n",
      "[Neuron Apoptosis @ step 2000] blocks.1.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0014]\n",
      "\n",
      "[Neuron Apoptosis @ step 2000] blocks.2.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0014]\n",
      "\n",
      "[Neuron Apoptosis @ step 2000] blocks.3.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0018]\n",
      "\n",
      "[Neuron Apoptosis @ step 2000] blocks.4.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0011]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running experiments:  85%|████████████████████████████████████████████████████████████████████████████████████████████████████████                   | 11/13 [26:48<03:01, 90.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Neuron Apoptosis @ step 2000] blocks.5.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0015]\n",
      "  Final loss: 0.0209\n",
      "  Events: 30\n",
      "\n",
      "[12/13] Testing: hybrid\n",
      "\n",
      "[Neuron Apoptosis @ step 500] blocks.0.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0001, 0.0009]\n",
      "\n",
      "[Neuron Apoptosis @ step 500] blocks.1.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0001, 0.0007]\n",
      "\n",
      "[Neuron Apoptosis @ step 500] blocks.2.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0008]\n",
      "\n",
      "[Neuron Apoptosis @ step 500] blocks.3.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0009]\n",
      "\n",
      "[Neuron Apoptosis @ step 500] blocks.4.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0007]\n",
      "\n",
      "[Neuron Apoptosis @ step 500] blocks.5.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0010]\n",
      "\n",
      "[Neuron Apoptosis @ step 1000] blocks.0.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0011]\n",
      "\n",
      "[Neuron Apoptosis @ step 1000] blocks.1.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0008]\n",
      "\n",
      "[Neuron Apoptosis @ step 1000] blocks.2.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0010]\n",
      "\n",
      "[Neuron Apoptosis @ step 1000] blocks.3.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0020]\n",
      "\n",
      "[Neuron Apoptosis @ step 1000] blocks.4.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0010]\n",
      "\n",
      "[Neuron Apoptosis @ step 1000] blocks.5.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0019]\n",
      "\n",
      "[Neuron Apoptosis @ step 1500] blocks.0.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0010]\n",
      "\n",
      "[Neuron Apoptosis @ step 1500] blocks.1.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0013]\n",
      "\n",
      "[Neuron Apoptosis @ step 1500] blocks.2.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0015]\n",
      "\n",
      "[Neuron Apoptosis @ step 1500] blocks.3.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0010]\n",
      "\n",
      "[Neuron Apoptosis @ step 1500] blocks.4.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0015]\n",
      "\n",
      "[Neuron Apoptosis @ step 1500] blocks.5.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0013]\n",
      "\n",
      "[Neuron Apoptosis @ step 2000] blocks.0.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0008]\n",
      "\n",
      "[Neuron Apoptosis @ step 2000] blocks.1.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0009]\n",
      "\n",
      "[Neuron Apoptosis @ step 2000] blocks.2.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0011]\n",
      "\n",
      "[Neuron Apoptosis @ step 2000] blocks.3.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0009]\n",
      "\n",
      "[Neuron Apoptosis @ step 2000] blocks.4.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0009]\n",
      "\n",
      "[Neuron Apoptosis @ step 2000] blocks.5.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0019]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running experiments:  92%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌         | 12/13 [28:00<01:24, 84.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Final loss: 0.0209\n",
      "  Events: 24\n",
      "\n",
      "[13/13] Testing: hybrid\n",
      "\n",
      "[Neuron Apoptosis @ step 600] blocks.0.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0001, 0.0007]\n",
      "\n",
      "[Neuron Apoptosis @ step 600] blocks.1.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0007]\n",
      "\n",
      "[Neuron Apoptosis @ step 600] blocks.2.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0007]\n",
      "\n",
      "[Neuron Apoptosis @ step 600] blocks.3.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0005]\n",
      "\n",
      "[Neuron Apoptosis @ step 600] blocks.4.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0006]\n",
      "\n",
      "[Neuron Apoptosis @ step 600] blocks.5.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0006]\n",
      "\n",
      "[Neuron Apoptosis @ step 1200] blocks.0.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0017]\n",
      "\n",
      "[Neuron Apoptosis @ step 1200] blocks.1.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0016]\n",
      "\n",
      "[Neuron Apoptosis @ step 1200] blocks.2.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0011]\n",
      "\n",
      "[Neuron Apoptosis @ step 1200] blocks.3.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0009]\n",
      "\n",
      "[Neuron Apoptosis @ step 1200] blocks.4.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0014]\n",
      "\n",
      "[Neuron Apoptosis @ step 1200] blocks.5.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0012]\n",
      "\n",
      "[Neuron Apoptosis @ step 1800] blocks.0.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0012]\n",
      "\n",
      "[Neuron Apoptosis @ step 1800] blocks.1.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0014]\n",
      "\n",
      "[Neuron Apoptosis @ step 1800] blocks.2.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0007]\n",
      "\n",
      "[Neuron Apoptosis @ step 1800] blocks.3.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0011]\n",
      "\n",
      "[Neuron Apoptosis @ step 1800] blocks.4.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0008]\n",
      "\n",
      "[Neuron Apoptosis @ step 1800] blocks.5.ffn.0\n",
      "  Pruning 51 neurons (bottom 10%)\n",
      "  Fitness range: [0.0000, 0.0012]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running experiments: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [29:11<00:00, 134.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Final loss: 0.0196\n",
      "  Events: 18\n",
      "\n",
      "Results saved to: sweep_results_20251120_185323.json\n",
      "\n",
      "======================================================================\n",
      "TOP CONFIGURATIONS\n",
      "======================================================================\n",
      "\n",
      "🏆 TOP 10 BY FINAL LOSS:\n",
      "\n",
      "1. FUNCTIONAL\n",
      "   Loss: 0.0190\n",
      "   Variance: 0.000025\n",
      "   Events: 24\n",
      "   Config: {'strategy': 'functional', 'prune_rate': 0.15, 'interval': 500, 'mutation_strength': 0.3}\n",
      "\n",
      "2. HYBRID\n",
      "   Loss: 0.0193\n",
      "   Variance: 0.000265\n",
      "   Events: 24\n",
      "   Config: {'strategy': 'hybrid', 'turnover_rate': 0.08, 'interval': 500, 'mutation_strength': 0.3}\n",
      "\n",
      "3. HYBRID\n",
      "   Loss: 0.0196\n",
      "   Variance: 0.001576\n",
      "   Events: 18\n",
      "   Config: {'strategy': 'hybrid', 'turnover_rate': 0.1, 'interval': 600, 'mutation_strength': 0.3}\n",
      "\n",
      "4. STANDARD\n",
      "   Loss: 0.0200\n",
      "   Variance: 0.004482\n",
      "   Events: 24\n",
      "   Config: {'strategy': 'standard', 'prune_rate': 0.15, 'interval': 500, 'mutation_strength': 0.3, 'fitness_metric': 'grad_activation', 'regrowth_strategy': 'mutation'}\n",
      "\n",
      "5. FUNCTIONAL\n",
      "   Loss: 0.0203\n",
      "   Variance: 0.000003\n",
      "   Events: 24\n",
      "   Config: {'strategy': 'functional', 'prune_rate': 0.1, 'interval': 500, 'mutation_strength': 0.3}\n",
      "\n",
      "6. HYBRID\n",
      "   Loss: 0.0203\n",
      "   Variance: 0.000014\n",
      "   Events: 24\n",
      "   Config: {'strategy': 'hybrid', 'turnover_rate': 0.05, 'interval': 500, 'mutation_strength': 0.3}\n",
      "\n",
      "7. HYBRID\n",
      "   Loss: 0.0205\n",
      "   Variance: 0.000011\n",
      "   Events: 30\n",
      "   Config: {'strategy': 'hybrid', 'turnover_rate': 0.05, 'interval': 400, 'mutation_strength': 0.3}\n",
      "\n",
      "8. HYBRID\n",
      "   Loss: 0.0206\n",
      "   Variance: 0.000009\n",
      "   Events: 18\n",
      "   Config: {'strategy': 'hybrid', 'turnover_rate': 0.05, 'interval': 600, 'mutation_strength': 0.3}\n",
      "\n",
      "9. STANDARD\n",
      "   Loss: 0.0207\n",
      "   Variance: 0.000783\n",
      "   Events: 24\n",
      "   Config: {'strategy': 'standard', 'prune_rate': 0.1, 'interval': 500, 'mutation_strength': 0.3, 'fitness_metric': 'grad_activation', 'regrowth_strategy': 'mutation'}\n",
      "\n",
      "10. HYBRID\n",
      "   Loss: 0.0208\n",
      "   Variance: 0.000092\n",
      "   Events: 30\n",
      "   Config: {'strategy': 'hybrid', 'turnover_rate': 0.08, 'interval': 400, 'mutation_strength': 0.3}\n",
      "\n",
      "======================================================================\n",
      "📊 TOP 10 BY STABILITY (Low Variance):\n",
      "\n",
      "1. FUNCTIONAL\n",
      "   Variance: 0.000003\n",
      "   Loss: 0.0203\n",
      "   Events: 24\n",
      "   Config: {'strategy': 'functional', 'prune_rate': 0.1, 'interval': 500, 'mutation_strength': 0.3}\n",
      "\n",
      "2. HYBRID\n",
      "   Variance: 0.000009\n",
      "   Loss: 0.0206\n",
      "   Events: 18\n",
      "   Config: {'strategy': 'hybrid', 'turnover_rate': 0.05, 'interval': 600, 'mutation_strength': 0.3}\n",
      "\n",
      "3. HYBRID\n",
      "   Variance: 0.000011\n",
      "   Loss: 0.0205\n",
      "   Events: 30\n",
      "   Config: {'strategy': 'hybrid', 'turnover_rate': 0.05, 'interval': 400, 'mutation_strength': 0.3}\n",
      "\n",
      "4. HYBRID\n",
      "   Variance: 0.000014\n",
      "   Loss: 0.0203\n",
      "   Events: 24\n",
      "   Config: {'strategy': 'hybrid', 'turnover_rate': 0.05, 'interval': 500, 'mutation_strength': 0.3}\n",
      "\n",
      "5. FUNCTIONAL\n",
      "   Variance: 0.000025\n",
      "   Loss: 0.0190\n",
      "   Events: 24\n",
      "   Config: {'strategy': 'functional', 'prune_rate': 0.15, 'interval': 500, 'mutation_strength': 0.3}\n",
      "\n",
      "6. HYBRID\n",
      "   Variance: 0.000070\n",
      "   Loss: 0.0208\n",
      "   Events: 18\n",
      "   Config: {'strategy': 'hybrid', 'turnover_rate': 0.08, 'interval': 600, 'mutation_strength': 0.3}\n",
      "\n",
      "7. HYBRID\n",
      "   Variance: 0.000092\n",
      "   Loss: 0.0208\n",
      "   Events: 30\n",
      "   Config: {'strategy': 'hybrid', 'turnover_rate': 0.08, 'interval': 400, 'mutation_strength': 0.3}\n",
      "\n",
      "8. HYBRID\n",
      "   Variance: 0.000265\n",
      "   Loss: 0.0193\n",
      "   Events: 24\n",
      "   Config: {'strategy': 'hybrid', 'turnover_rate': 0.08, 'interval': 500, 'mutation_strength': 0.3}\n",
      "\n",
      "9. HYBRID\n",
      "   Variance: 0.000374\n",
      "   Loss: 0.0209\n",
      "   Events: 30\n",
      "   Config: {'strategy': 'hybrid', 'turnover_rate': 0.1, 'interval': 400, 'mutation_strength': 0.3}\n",
      "\n",
      "10. STANDARD\n",
      "   Variance: 0.000783\n",
      "   Loss: 0.0207\n",
      "   Events: 24\n",
      "   Config: {'strategy': 'standard', 'prune_rate': 0.1, 'interval': 500, 'mutation_strength': 0.3, 'fitness_metric': 'grad_activation', 'regrowth_strategy': 'mutation'}\n",
      "\n",
      "======================================================================\n",
      "🎯 BEST CONFIG PER STRATEGY:\n",
      "\n",
      "FUNCTIONAL:\n",
      "   Loss: 0.0190\n",
      "   Variance: 0.000025\n",
      "   Events: 24\n",
      "   Config: {'strategy': 'functional', 'prune_rate': 0.15, 'interval': 500, 'mutation_strength': 0.3}\n",
      "\n",
      "HYBRID:\n",
      "   Loss: 0.0193\n",
      "   Variance: 0.000265\n",
      "   Events: 24\n",
      "   Config: {'strategy': 'hybrid', 'turnover_rate': 0.08, 'interval': 500, 'mutation_strength': 0.3}\n",
      "\n",
      "STANDARD:\n",
      "   Loss: 0.0200\n",
      "   Variance: 0.004482\n",
      "   Events: 24\n",
      "   Config: {'strategy': 'standard', 'prune_rate': 0.15, 'interval': 500, 'mutation_strength': 0.3, 'fitness_metric': 'grad_activation', 'regrowth_strategy': 'mutation'}\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run quick sweep (13 configs)\n",
    "\n",
    "sweep = QuickSweep(\n",
    "    model_class=ApoptoticTransformer,\n",
    "    train_dataset=shakespeare_dataset,\n",
    "    val_dataset=shakespeare_dataset,\n",
    "    device=device,\n",
    "    tokenizer=tokenizer,\n",
    "    num_steps=2000,\n",
    "    eval_interval=100\n",
    ")\n",
    "\n",
    "print(\"Starting hyperparameter sweep...\")\n",
    "sweep.run_sweep()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "TOP CONFIGURATIONS\n",
      "======================================================================\n",
      "\n",
      "Baseline: 0.0189\n",
      "\n",
      "Top 5:\n",
      "\n",
      "1. FUNCTIONAL\n",
      "   Loss: 0.0190 (+0.0001, +0.3% from baseline)\n",
      "   Variance: 0.000025\n",
      "   Events: 24\n",
      "   Config: {'strategy': 'functional', 'prune_rate': 0.15, 'interval': 500, 'mutation_strength': 0.3}\n",
      "\n",
      "2. HYBRID\n",
      "   Loss: 0.0193 (+0.0004, +1.9% from baseline)\n",
      "   Variance: 0.000265\n",
      "   Events: 24\n",
      "   Config: {'strategy': 'hybrid', 'turnover_rate': 0.08, 'interval': 500, 'mutation_strength': 0.3}\n",
      "\n",
      "3. HYBRID\n",
      "   Loss: 0.0196 (+0.0007, +3.8% from baseline)\n",
      "   Variance: 0.001576\n",
      "   Events: 18\n",
      "   Config: {'strategy': 'hybrid', 'turnover_rate': 0.1, 'interval': 600, 'mutation_strength': 0.3}\n",
      "\n",
      "4. STANDARD\n",
      "   Loss: 0.0200 (+0.0010, +5.5% from baseline)\n",
      "   Variance: 0.004482\n",
      "   Events: 24\n",
      "   Config: {'strategy': 'standard', 'prune_rate': 0.15, 'interval': 500, 'mutation_strength': 0.3, 'fitness_metric': 'grad_activation', 'regrowth_strategy': 'mutation'}\n",
      "\n",
      "5. FUNCTIONAL\n",
      "   Loss: 0.0203 (+0.0014, +7.4% from baseline)\n",
      "   Variance: 0.000003\n",
      "   Events: 24\n",
      "   Config: {'strategy': 'functional', 'prune_rate': 0.1, 'interval': 500, 'mutation_strength': 0.3}\n"
     ]
    }
   ],
   "source": [
    "# Print top results\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TOP CONFIGURATIONS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "valid_results = [r for r in sweep.results if 'error' not in r]\n",
    "sorted_results = sorted(valid_results, key=lambda x: x['final_train_loss'])\n",
    "\n",
    "print(f\"\\nBaseline: {baseline_final_loss:.4f}\")\n",
    "print(\"\\nTop 5:\")\n",
    "\n",
    "for i, result in enumerate(sorted_results[:5], 1):\n",
    "    config = result['config']\n",
    "    loss = result['final_train_loss']\n",
    "    variance = result['train_loss_variance']\n",
    "    \n",
    "    diff = loss - baseline_final_loss\n",
    "    pct = (diff / baseline_final_loss) * 100\n",
    "    \n",
    "    print(f\"\\n{i}. {config['strategy'].upper()}\")\n",
    "    print(f\"   Loss: {loss:.4f} ({diff:+.4f}, {pct:+.1f}% from baseline)\")\n",
    "    print(f\"   Variance: {variance:.6f}\")\n",
    "    print(f\"   Events: {result['num_events']}\")\n",
    "    print(f\"   Config: {config}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate Winner (5K Steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating best config: functional\n",
      "Expected loss: ~0.0190\n",
      "\n",
      "Training for 5000 steps...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████████▊                                                                                                                    | 499/5000 [00:15<02:15, 33.24it/s, loss=0.071]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Neuron Apoptosis @ step 500] blocks.0.ffn.0\n",
      "  Pruning 76 neurons (bottom 15%)\n",
      "  Fitness range: [0.0001, 0.0006]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████████▊                                                                                                                    | 499/5000 [00:25<02:15, 33.24it/s, loss=0.071]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Neuron Apoptosis @ step 500] blocks.1.ffn.0\n",
      "  Pruning 76 neurons (bottom 15%)\n",
      "  Fitness range: [0.0001, 0.0006]\n",
      "\n",
      "[Neuron Apoptosis @ step 500] blocks.2.ffn.0\n",
      "  Pruning 76 neurons (bottom 15%)\n",
      "  Fitness range: [0.0000, 0.0007]\n",
      "\n",
      "[Neuron Apoptosis @ step 500] blocks.3.ffn.0\n",
      "  Pruning 76 neurons (bottom 15%)\n",
      "  Fitness range: [0.0000, 0.0006]\n",
      "\n",
      "[Neuron Apoptosis @ step 500] blocks.4.ffn.0\n",
      "  Pruning 76 neurons (bottom 15%)\n",
      "  Fitness range: [0.0000, 0.0007]\n",
      "\n",
      "[Neuron Apoptosis @ step 500] blocks.5.ffn.0\n",
      "  Pruning 76 neurons (bottom 15%)\n",
      "  Fitness range: [0.0000, 0.0010]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█████████████████████████▊                                                                                                       | 999/5000 [02:37<02:04, 32.12it/s, loss=0.022]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Neuron Apoptosis @ step 1000] blocks.0.ffn.0\n",
      "  Pruning 76 neurons (bottom 15%)\n",
      "  Fitness range: [0.0000, 0.0005]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█████████████████████████▊                                                                                                       | 999/5000 [02:55<02:04, 32.12it/s, loss=0.022]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Neuron Apoptosis @ step 1000] blocks.1.ffn.0\n",
      "  Pruning 76 neurons (bottom 15%)\n",
      "  Fitness range: [0.0000, 0.0006]\n",
      "\n",
      "[Neuron Apoptosis @ step 1000] blocks.2.ffn.0\n",
      "  Pruning 76 neurons (bottom 15%)\n",
      "  Fitness range: [0.0000, 0.0005]\n",
      "\n",
      "[Neuron Apoptosis @ step 1000] blocks.3.ffn.0\n",
      "  Pruning 76 neurons (bottom 15%)\n",
      "  Fitness range: [0.0000, 0.0010]\n",
      "\n",
      "[Neuron Apoptosis @ step 1000] blocks.4.ffn.0\n",
      "  Pruning 76 neurons (bottom 15%)\n",
      "  Fitness range: [0.0000, 0.0006]\n",
      "\n",
      "[Neuron Apoptosis @ step 1000] blocks.5.ffn.0\n",
      "  Pruning 76 neurons (bottom 15%)\n",
      "  Fitness range: [0.0000, 0.0011]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██████████████████████████████████████▎                                                                                         | 1498/5000 [04:56<01:47, 32.60it/s, loss=0.025]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Neuron Apoptosis @ step 1500] blocks.0.ffn.0\n",
      "  Pruning 76 neurons (bottom 15%)\n",
      "  Fitness range: [0.0000, 0.0006]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██████████████████████████████████████▎                                                                                         | 1499/5000 [05:16<01:47, 32.60it/s, loss=0.025]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Neuron Apoptosis @ step 1500] blocks.1.ffn.0\n",
      "  Pruning 76 neurons (bottom 15%)\n",
      "  Fitness range: [0.0000, 0.0010]\n",
      "\n",
      "[Neuron Apoptosis @ step 1500] blocks.2.ffn.0\n",
      "  Pruning 76 neurons (bottom 15%)\n",
      "  Fitness range: [0.0000, 0.0006]\n",
      "\n",
      "[Neuron Apoptosis @ step 1500] blocks.3.ffn.0\n",
      "  Pruning 76 neurons (bottom 15%)\n",
      "  Fitness range: [0.0000, 0.0007]\n",
      "\n",
      "[Neuron Apoptosis @ step 1500] blocks.4.ffn.0\n",
      "  Pruning 76 neurons (bottom 15%)\n",
      "  Fitness range: [0.0000, 0.0006]\n",
      "\n",
      "[Neuron Apoptosis @ step 1500] blocks.5.ffn.0\n",
      "  Pruning 76 neurons (bottom 15%)\n",
      "  Fitness range: [0.0000, 0.0014]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███████████████████████████████████████████████████                                                                             | 1997/5000 [07:30<01:31, 32.79it/s, loss=0.019]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Neuron Apoptosis @ step 2000] blocks.0.ffn.0\n",
      "  Pruning 76 neurons (bottom 15%)\n",
      "  Fitness range: [0.0000, 0.0011]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███████████████████████████████████████████████████▏                                                                            | 1999/5000 [07:46<01:31, 32.79it/s, loss=0.019]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Neuron Apoptosis @ step 2000] blocks.1.ffn.0\n",
      "  Pruning 76 neurons (bottom 15%)\n",
      "  Fitness range: [0.0000, 0.0008]\n",
      "\n",
      "[Neuron Apoptosis @ step 2000] blocks.2.ffn.0\n",
      "  Pruning 76 neurons (bottom 15%)\n",
      "  Fitness range: [0.0000, 0.0010]\n",
      "\n",
      "[Neuron Apoptosis @ step 2000] blocks.3.ffn.0\n",
      "  Pruning 76 neurons (bottom 15%)\n",
      "  Fitness range: [0.0000, 0.0005]\n"
     ]
    }
   ],
   "source": [
    "# Get best config from sweep\n",
    "best_result = sorted_results[0]\n",
    "best_config = best_result['config']\n",
    "\n",
    "print(f\"Validating best config: {best_config['strategy']}\")\n",
    "print(f\"Expected loss: ~{best_result['final_train_loss']:.4f}\")\n",
    "\n",
    "# Create model with best config\n",
    "validation_model = ApoptoticTransformer(\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    "    d_model=128,\n",
    "    n_heads=4,\n",
    "    n_layers=6,\n",
    "    max_seq_len=128\n",
    ").to(device)\n",
    "\n",
    "# Create manager based on strategy\n",
    "target_layers = [f'blocks.{i}.ffn.0' for i in range(6)]\n",
    "\n",
    "if best_config['strategy'] == 'standard':\n",
    "    manager = NeuronApoptosisManager(\n",
    "        model=validation_model,\n",
    "        target_layers=target_layers,\n",
    "        **{k: v for k, v in best_config.items() if k != 'strategy'}\n",
    "    )\n",
    "elif best_config['strategy'] == 'functional':\n",
    "    manager = FunctionalPreservationApoptosis(\n",
    "        model=validation_model,\n",
    "        target_layers=target_layers,\n",
    "        **{k: v for k, v in best_config.items() if k != 'strategy' and k != 'interval'}\n",
    "    )\n",
    "elif best_config['strategy'] == 'hybrid':\n",
    "    manager = HybridGrowthAndDeath(\n",
    "        model=validation_model,\n",
    "        target_layers=target_layers,\n",
    "        **{k: v for k, v in best_config.items() if k != 'strategy'}\n",
    "    )\n",
    "\n",
    "# Train for 5K steps\n",
    "optimizer = torch.optim.AdamW(validation_model.parameters(), lr=3e-4)\n",
    "val_losses = []\n",
    "train_iter = iter(train_loader)\n",
    "\n",
    "print(\"\\nTraining for 5000 steps...\")\n",
    "pbar = tqdm(total=5000)\n",
    "\n",
    "for step in range(5000):\n",
    "    try:\n",
    "        x, y = next(train_iter)\n",
    "    except StopIteration:\n",
    "        train_iter = iter(train_loader)\n",
    "        x, y = next(train_iter)\n",
    "    \n",
    "    x, y = x.to(device), y.to(device)\n",
    "    \n",
    "    validation_model.train()\n",
    "    logits = validation_model(x)\n",
    "    loss = criterion(logits.reshape(-1, logits.size(-1)), y.reshape(-1))\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(validation_model.parameters(), max_norm=1.0)\n",
    "    optimizer.step()\n",
    "    \n",
    "    manager.step()\n",
    "    \n",
    "    val_losses.append(loss.item())\n",
    "    \n",
    "    if step % 100 == 0:\n",
    "        pbar.set_postfix({'loss': f'{loss.item():.3f}'})\n",
    "    pbar.update(1)\n",
    "\n",
    "pbar.close()\n",
    "\n",
    "validation_final_loss = np.mean(val_losses[-100:])\n",
    "print(f\"\\n✓ Validation complete!\")\n",
    "print(f\"\\nFinal Results:\")\n",
    "print(f\"  Baseline:   {baseline_final_loss:.4f}\")\n",
    "print(f\"  Best config: {validation_final_loss:.4f}\")\n",
    "print(f\"  Difference: {validation_final_loss - baseline_final_loss:+.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Save sweep results\n",
    "with open(f'results/sweep_{timestamp}.json', 'w') as f:\n",
    "    json.dump(sweep.results, f, indent=2)\n",
    "\n",
    "# Save validation results\n",
    "validation_results = {\n",
    "    'config': best_config,\n",
    "    'baseline_loss': baseline_final_loss,\n",
    "    'validation_loss': validation_final_loss,\n",
    "    'num_events': len(manager.apoptosis_events) if hasattr(manager, 'apoptosis_events') else 0,\n",
    "    'timestamp': timestamp\n",
    "}\n",
    "\n",
    "with open(f'results/validation_{timestamp}.json', 'w') as f:\n",
    "    json.dump(validation_results, f, indent=2)\n",
    "\n",
    "print(f\"✓ Results saved to results/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. Update `EXPERIMENT_LOG.md` with results\n",
    "2. Try Taguchi optimization for faster search\n",
    "3. Test domain shift (Shakespeare → Wikipedia)\n",
    "4. Visualize neuron lineages"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
